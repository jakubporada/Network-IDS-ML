{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f0f3be5-b639-45aa-9e6a-fdb071ba247e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')  # Add parent directory to path\n",
    "\n",
    "from src.preprocessing.data_processor import NetworkDataProcessor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "print(\"Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5100cb9-c81e-4848-bcb9-f6b235573383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files to process: 1\n",
      "  - Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\n"
     ]
    }
   ],
   "source": [
    "file_paths = [\n",
    "    '../data/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv',\n",
    "]\n",
    "\n",
    "print(f\"Files to process: {len(file_paths)}\")\n",
    "for f in file_paths:\n",
    "    print(f\"  - {f.split('/')[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29adce36-3070-4b9c-9b58-f6b3317dd969",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "NETWORK IDS - DATA PREPROCESSING PIPELINE\n",
      "======================================================================\n",
      "Loading data files...\n",
      "  Loading Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv...\n",
      "✓ Loaded 225,745 total rows\n",
      "✓ Cleaned 79 column names\n",
      "\n",
      "Cleaning data...\n",
      "  Found 68 missing/infinity values\n",
      "✓ Cleaned data: 225,711 rows remaining\n",
      "✓ Removed 2,629 duplicate rows\n",
      "\n",
      "Label distribution:\n",
      "  BENIGN: 95,068 (42.6%)\n",
      "  ATTACK: 128,014 (57.4%)\n",
      "\n",
      "✓ Prepared 78 features\n",
      "\n",
      "✓ Train set: 178,465 rows\n",
      "✓ Test set: 44,617 rows\n",
      "\n",
      "Scaling features...\n",
      "✓ Features scaled\n",
      "✓ Saved preprocessor to ../models/preprocessor.pkl\n",
      "\n",
      "======================================================================\n",
      "PREPROCESSING COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Final shapes:\n",
      "X_train: (178465, 78)\n",
      "X_test: (44617, 78)\n",
      "y_train: (178465,)\n",
      "y_test: (44617,)\n"
     ]
    }
   ],
   "source": [
    "# Create processor\n",
    "processor = NetworkDataProcessor()\n",
    "\n",
    "# Run complete pipeline\n",
    "X_train, X_test, y_train, y_test = processor.full_pipeline(\n",
    "    file_paths=file_paths,\n",
    "    save_path='../models/'\n",
    ")\n",
    "\n",
    "print(\"\\nFinal shapes:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "001c17bf-9dce-4f65-b42c-ef7ab8e3c1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data files...\n",
      "  Loading Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv...\n",
      "✓ Loaded 225,745 total rows\n",
      "✓ Cleaned 79 column names\n",
      "\n",
      "Cleaning data...\n",
      "  Found 68 missing/infinity values\n",
      "✓ Cleaned data: 225,711 rows remaining\n",
      "✓ Removed 2,629 duplicate rows\n",
      "\n",
      "Label distribution:\n",
      "  BENIGN: 95,068 (42.6%)\n",
      "  ATTACK: 128,014 (57.4%)\n",
      "\n",
      "✓ Prepared 78 features\n",
      "✓ Saved unscaled test data\n",
      "Shape: (44617, 78)\n",
      "Sample values (first 5): [5.482300e+04 4.916412e+06 1.000000e+00 5.000000e+00 6.000000e+00]\n",
      "These should be real numbers (like 80, 12000, 500), not scaled (-0.4, 0.2, etc.)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "df = processor.load_multiple_files(file_paths)\n",
    "df = processor.clean_column_names(df)\n",
    "df = processor.handle_infinity_and_missing(df)\n",
    "df = processor.remove_duplicates(df)\n",
    "df = processor.create_binary_labels(df)\n",
    "X, y = processor.prepare_features(df)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_unscaled, X_test_unscaled, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "np.save('../data/processed/X_train_unscaled.npy', X_train_unscaled.values)\n",
    "np.save('../data/processed/X_test_unscaled.npy', X_test_unscaled.values)\n",
    "\n",
    "print(\" Saved unscaled test data\")\n",
    "print(f\"Shape: {X_test_unscaled.shape}\")\n",
    "print(f\"Sample values (first 5): {X_test_unscaled.values[0][:5]}\")\n",
    "print(\"These should be real numbers (like 80, 12000, 500), not scaled (-0.4, 0.2, etc.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e270ca97-7fc7-4911-85c7-400c7e954cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verification:\n",
      "Loaded X_train shape: (178465, 78)\n",
      "Loaded y_train shape: (178465,)\n",
      "\n",
      "Class distribution in training set:\n",
      "  BENIGN: 76,054 (42.6%)\n",
      "  ATTACK: 102,411 (57.4%)\n"
     ]
    }
   ],
   "source": [
    "X_train_check = np.load('../data/processed/X_train.npy')\n",
    "y_train_check = np.load('../data/processed/y_train.npy')\n",
    "\n",
    "print(f\"\\nVerification:\")\n",
    "print(f\"Loaded X_train shape: {X_train_check.shape}\")\n",
    "print(f\"Loaded y_train shape: {y_train_check.shape}\")\n",
    "\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "unique, counts = np.unique(y_train_check, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    label_name = \"BENIGN\" if label == 0 else \"ATTACK\"\n",
    "    print(f\"  {label_name}: {count:,} ({count/len(y_train_check)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f1b479-ad32-4696-9d88-c7dd5d780329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb3250a-7c17-45e5-b925-b557450573ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
