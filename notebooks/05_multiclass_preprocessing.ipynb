{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90eab5ac-14af-440b-ac48-1f31fd7df957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MULTI-CLASS IDS - DATA PREPROCESSING\n",
      "======================================================================\n",
      "Loading data files...\n",
      "  Loading Monday-WorkingHours.pcap_ISCX.csv...\n",
      "  Loading Tuesday-WorkingHours.pcap_ISCX.csv...\n",
      "  Loading Wednesday-workingHours.pcap_ISCX.csv...\n",
      "  Loading Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv...\n",
      "  Loading Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv...\n",
      "  Loading Friday-WorkingHours-Morning.pcap_ISCX.csv...\n",
      "  Loading Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv...\n",
      "  Loading Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv...\n",
      "✓ Loaded 2,830,743 total rows\n",
      "\n",
      "Total flows loaded: 2,830,743\n",
      "✓ Cleaned 79 column names\n",
      "\n",
      "Cleaning data...\n",
      "  Found 5,734 missing/infinity values\n",
      "✓ Cleaned data: 2,827,876 rows remaining\n",
      "✓ Removed 307,078 duplicate rows\n",
      "\n",
      "Label distribution:\n",
      "Label\n",
      "BENIGN                        2095057\n",
      "DoS Hulk                       172846\n",
      "DDoS                           128014\n",
      "PortScan                        90694\n",
      "DoS GoldenEye                   10286\n",
      "FTP-Patator                      5931\n",
      "DoS slowloris                    5385\n",
      "DoS Slowhttptest                 5228\n",
      "SSH-Patator                      3219\n",
      "Bot                              1948\n",
      "Web Attack - Brute Force         1470\n",
      "Web Attack - XSS                  652\n",
      "Infiltration                       36\n",
      "Web Attack - Sql Injection         21\n",
      "Heartbleed                         11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Encoded labels:\n",
      "  0: BENIGN\n",
      "  1: Bot\n",
      "  2: DDoS\n",
      "  3: DoS GoldenEye\n",
      "  4: DoS Hulk\n",
      "  5: DoS Slowhttptest\n",
      "  6: DoS slowloris\n",
      "  7: FTP-Patator\n",
      "  8: Heartbleed\n",
      "  9: Infiltration\n",
      "  10: PortScan\n",
      "  11: SSH-Patator\n",
      "  12: Web Attack - Brute Force\n",
      "  13: Web Attack - Sql Injection\n",
      "  14: Web Attack - XSS\n",
      "\n",
      " Prepared 78 features\n",
      "\n",
      " Train set: 2,016,638 flows\n",
      " Test set: 504,160 flows\n",
      " Features scaled\n",
      "\n",
      " Saved all processed data to data/processed_multiclass/\n",
      " Saved preprocessor to models/preprocessor_multiclass.pkl\n",
      "\n",
      "======================================================================\n",
      "PREPROCESSING COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.preprocessing.data_processor import NetworkDataProcessor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MULTI-CLASS IDS - DATA PREPROCESSING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "file_paths = [\n",
    "    '../data/Monday-WorkingHours.pcap_ISCX.csv',\n",
    "    '../data/Tuesday-WorkingHours.pcap_ISCX.csv',\n",
    "    '../data/Wednesday-workingHours.pcap_ISCX.csv',\n",
    "    '../data/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv',\n",
    "    '../data/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv',\n",
    "    '../data/Friday-WorkingHours-Morning.pcap_ISCX.csv',\n",
    "    '../data/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv',\n",
    "    '../data/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv',\n",
    "]\n",
    "\n",
    "processor = NetworkDataProcessor()\n",
    "\n",
    "df = processor.load_multiple_files(file_paths)\n",
    "print(f\"\\nTotal flows loaded: {len(df):,}\")\n",
    "\n",
    "df = processor.clean_column_names(df)\n",
    "\n",
    "df['Label'] = df['Label'].str.replace('�', '-', regex=False)\n",
    "df['Label'] = df['Label'].str.strip()\n",
    "\n",
    "df = processor.handle_infinity_and_missing(df)\n",
    "df = processor.remove_duplicates(df)\n",
    "\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df['Label'].value_counts())\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['Label'])\n",
    "\n",
    "print(f\"\\nEncoded labels:\")\n",
    "for i, label in enumerate(label_encoder.classes_):\n",
    "    print(f\"  {i}: {label}\")\n",
    "\n",
    "X = df.drop(['Label'], axis=1)\n",
    "X = X.select_dtypes(include=[np.number])\n",
    "\n",
    "feature_columns = X.columns.tolist()\n",
    "print(f\"\\n Prepared {len(feature_columns)} features\")\n",
    "\n",
    "X_train_unscaled, X_test_unscaled, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\n Train set: {len(X_train_unscaled):,} flows\")\n",
    "print(f\" Test set: {len(X_test_unscaled):,} flows\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_unscaled)\n",
    "X_test_scaled = scaler.transform(X_test_unscaled)\n",
    "\n",
    "print(\" Features scaled\")\n",
    "\n",
    "import os\n",
    "os.makedirs('../data/processed_multiclass', exist_ok=True)\n",
    "\n",
    "np.save('../data/processed_multiclass/X_train_scaled.npy', X_train_scaled)\n",
    "np.save('../data/processed_multiclass/X_test_scaled.npy', X_test_scaled)\n",
    "np.save('../data/processed_multiclass/X_train_unscaled.npy', X_train_unscaled.values)\n",
    "np.save('../data/processed_multiclass/X_test_unscaled.npy', X_test_unscaled.values)\n",
    "np.save('../data/processed_multiclass/y_train.npy', y_train)\n",
    "np.save('../data/processed_multiclass/y_test.npy', y_test)\n",
    "\n",
    "# Save preprocessor with label encoder\n",
    "joblib.dump({\n",
    "    'scaler': scaler,\n",
    "    'feature_columns': feature_columns,\n",
    "    'label_encoder': label_encoder,\n",
    "    'classes': label_encoder.classes_.tolist()\n",
    "}, '../models/preprocessor_multiclass.pkl')\n",
    "\n",
    "print(\"\\n Saved all processed data to data/processed_multiclass/\")\n",
    "print(\" Saved preprocessor to models/preprocessor_multiclass.pkl\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREPROCESSING COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bed1184-06fa-42b2-a358-e8a06146949d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
